{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "import numpy\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*-coding:utf-8 -*-\n",
    "# import jieba.analyse\n",
    "# import jieba\n",
    "# import os\n",
    "# #添加专有名词，增加分词力度\n",
    "# jieba.suggest_freq('中国社科院研究生院', True)\n",
    "# jieba.suggest_freq('德国ZF集团', True)\n",
    "# jieba.suggest_freq('技术换市场', True)\n",
    "# jieba.suggest_freq('中央企业', True)\n",
    "# jieba.suggest_freq('工作会议', True)\n",
    "# jieba.suggest_freq('国资委主任', True)\n",
    " \n",
    "# raw_data_path = 'F:/sougou_data/'\n",
    "# cut_data_path = 'F:/sougou_cutdata/'\n",
    "# stop_word_path = 'F:/sougou_cutdata/stopwords.txt'\n",
    " \n",
    "# def stopwordslist(filepath):\n",
    "#     stopwords = [line.strip() for line in open(filepath, 'rb').readlines()]\n",
    "#     return stopwords\n",
    " \n",
    "# def cut_word(raw_data_path, cut_data_path ):\n",
    "#     data_file_list = os.listdir(raw_data_path)\n",
    "#     corpus = ''\n",
    "#     temp = 0\n",
    "#     for file in data_file_list:\n",
    "#         with open(raw_data_path + file,'rb') as f:\n",
    "#             print(temp+1)\n",
    "#             temp +=1\n",
    "#             document = f.read()\n",
    "#             document_cut = jieba.cut(document, cut_all=False)\n",
    "#             # print('/'.join(document_cut))\n",
    "#             result = ' '.join(document_cut)\n",
    "#             corpus += result\n",
    "#           #  print(result)\n",
    "#     with open(cut_data_path + 'corpus.txt', 'w+', encoding='utf-8') as f:\n",
    "#         f.write(corpus)  # 读取的方式和写入的方式要一致\n",
    " \n",
    "#     stopwords = stopwordslist(stop_word_path)  # 这里加载停用词的路径\n",
    "#     with open(cut_data_path + 'corpus.txt', 'r', encoding='utf-8') as f:\n",
    "#         document_cut = f.read()\n",
    "#         outstr = ''\n",
    "#         for word in document_cut:\n",
    "#             if word not in stopwords:\n",
    "#                 if word != '\\t':\n",
    "#                     outstr += word\n",
    "#                     outstr += \" \"\n",
    " \n",
    "#     with open(cut_data_path + 'corpus1.txt', 'w+', encoding='utf-8') as f:\n",
    "#             f.write(outstr)  # 读取的方式和写入的方式要一致\n",
    " \n",
    "# if __name__ == \"__main__\":\n",
    "#     cut_word(raw_data_path, cut_data_path )\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
